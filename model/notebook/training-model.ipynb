{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
      "Requirement already satisfied: transformers in d:\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (4.48.3)\n",
      "Collecting tensorflow (from -r requirements.txt (line 4))\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\miniconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (5.29.3)\n",
      "Requirement already satisfied: setuptools in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers->-r requirements.txt (line 3)) (2025.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 3)) (2024.12.14)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.44.0)\n",
      "Requirement already satisfied: rich in d:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (13.9.4)\n",
      "Requirement already satisfied: namex in d:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 4)) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-kerasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in d:\\miniconda3\\lib\\site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in d:\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in d:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in d:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\miniconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Using cached tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: enron methanol ; meter # : 988291\\r\\n...     0\n",
       "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...     0\n",
       "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...     0\n",
       "3  Subject: photoshop , windows , office . cheap ...     1\n",
       "4  Subject: re : indian springs\\r\\nthis deal is t...     0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_ds = pd.read_csv('./model/datasets/emails_dataset.csv')\n",
    "email_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(email_ds['text'], email_ds['spam'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('email_spam_model\\\\tokenizer_config.json',\n",
       " 'email_spam_model\\\\special_tokens_map.json',\n",
       " 'email_spam_model\\\\vocab.txt',\n",
       " 'email_spam_model\\\\added_tokens.json',\n",
       " 'email_spam_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer.save_pretrained(\"./model/email_spam_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch Dataset\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  3395,  1024,  2128,  1024,  2034,  6959,  1011, 16060, 22684,\n",
       "          1041,  1004,  1052,  2047,  3066,  2193,  2003, 22777, 18139,  2487,\n",
       "          6294,  3044,  1030, 14925,  2102,  6021,  1013,  2676,  1013,  2456,\n",
       "          6185,  1024,  2484,  7610,  2000,  1024,  3419, 28794,  1013, 13058,\n",
       "          1013,  4372,  4948,  1030,  4372,  4948,  1010,  7628, 11527,  2015,\n",
       "          1013,  7570,  2226,  1013, 14925,  2102,  1030, 14925,  2102, 10507,\n",
       "          1024,  3395,  1024,  2128,  1024,  2034,  6959,  1011, 16060, 22684,\n",
       "          1041,  1004,  1052,  3419,  1024,  2052,  2017,  3531,  2275,  2039,\n",
       "          2178,  2028,  3204,  7281,  2005,  1996,  2917,  1006,  2197,  3204,\n",
       "          2001, 19235, 28311,  2509,  1007,  1029,  7628,  1024,  2566,  9606,\n",
       "          1005,  1055,  3602,  3531,  2079,  2025,  4604,  2041,  2151,  3259,\n",
       "          2006,  2023,  1012,  2057,  5987,  1996,  3259,  2306,  1037,  2154,\n",
       "          2030,  2061,  1012,  3531,  2292,  2033,  2113,  2065,  2017,  2031,\n",
       "          2151,  3980,  1010,  4283,  1010,  8040,  2015,  1060, 21211, 17465,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  2830,  2098,  2011,  6294,  3044,  1013,  7570,  2226,\n",
       "          1013, 14925,  2102,  2006,  6021,  1013,  2676,  1013,  2456,  6185,\n",
       "          1024,  2322,  7610,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          4372,  4948,  2167,  2637, 13058,  1012,  2013,  1024,  9606,  9729,\n",
       "          6021,  1013,  2676,  1013,  2456,  6185,  1024,  2260,  7610,  2000,\n",
       "          1024,  6294,  3044,  1013,  7570,  2226,  1013, 14925,  2102,  1030,\n",
       "         14925,  2102, 10507,  1024,  3395,  1024,  2128,  1024,  2034,  6959,\n",
       "          1011, 16060, 22684,  1041,  1004,  1052,  2748,  1010,  2021,  1045,\n",
       "          2052,  5227,  2008,  7628,  2025,  4604,  2041,  3259,  2144,  2023,\n",
       "          2323,  2022,  2067,  2772,  3859,  1012,  1045,  4384,  1996,  3066,\n",
       "         16672,  7303,  2917,  1006,  2029,  3419,  2275,  2039,  2004,  3066,\n",
       "         19235, 28311,  2509,  1007,  2003,  4987,  2000,  1037,  5462,  8269,\n",
       "          3820,  2008,  2515,  2025,  3104,  2023,  8316,  1012,  9606,  6294,\n",
       "          3044,  6021,  1013,  2676,  1013,  2456,  2260,  1024,  2676,  7610,\n",
       "          2000,  1024,  9606,  9729,  1013,  7570,  2226,  1013, 14925,  2102,\n",
       "          1030, 14925,  2102, 10507,  1024,  3395,  1024,  2034,  6959,  1011,\n",
       "         16060, 22684,  1041,  1004,  1052,  2064,  2057,  2074,  2224,  2023,\n",
       "          2005,  2258,  2738,  2059,  5128,  1999,  1037,  2028,  3204,  3813,\n",
       "          7281,  1006,  2144,  2057,  2123,  2102,  2031,  3259,  4312,  1007,\n",
       "          1029,  4283,  1010,  8040,  2015,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  2830,  2098,  2011,\n",
       "          6294,  3044,  1013,  7570,  2226,  1013, 14925,  2102,  2006,  6021,\n",
       "          1013,  2676,  1013,  2456,  2260,  1024,  2484,  7610,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "          1011,  1011,  1011,  1011,  1011, 16672,  1048,  4202,  6021,  1013,\n",
       "          6021,  1013,  2456,  5840,  1024,  2382,  7610,  2000,  1024,  3419,\n",
       "         28794,  1013, 13058,  1013,  4372,  4948,  1030,  4372,  4948, 10507,\n",
       "          1024,  7628, 11527,  2015,  1013,  7570,  2226,  1013, 14925,  2102,\n",
       "          1030, 14925,  2102,  1010,  6294,  3044,  1013,  7570,  2226,  1013,\n",
       "         14925,  2102,  1030, 14925,  2102,  1010,  6221,  1052, 27788, 13778,\n",
       "          1013,  7570,  2226,  1013, 14925,  2102,  1030, 14925,  2102,  1010,\n",
       "          9606,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = EmailDataset(train_encodings, y_train.tolist())\n",
    "test_dataset = EmailDataset(test_encodings, y_test.tolist())\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model/results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/70 [02:58<?, ?it/s]\n",
      "  1%|          | 10/1090 [01:08<2:05:03,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7018, 'grad_norm': 2.616570472717285, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1090 [02:23<2:13:03,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6823, 'grad_norm': 1.4500535726547241, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1090 [03:38<2:11:28,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6478, 'grad_norm': 1.1301486492156982, 'learning_rate': 3e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 40/1090 [04:52<2:09:24,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.623, 'grad_norm': 1.2964814901351929, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 50/1090 [06:03<2:05:35,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5482, 'grad_norm': 2.8508880138397217, 'learning_rate': 5e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1090 [07:17<2:07:09,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5202, 'grad_norm': 1.7294577360153198, 'learning_rate': 6e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 70/1090 [08:28<2:01:49,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4657, 'grad_norm': 1.7442193031311035, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 80/1090 [09:40<1:59:46,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4325, 'grad_norm': 2.0070817470550537, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 90/1090 [10:51<1:59:07,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3386, 'grad_norm': 3.619962215423584, 'learning_rate': 9e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 100/1090 [12:03<1:57:41,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2752, 'grad_norm': 2.385684013366699, 'learning_rate': 1e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 110/1090 [13:16<2:00:41,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2219, 'grad_norm': 1.5647664070129395, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 120/1090 [14:30<1:57:52,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2214, 'grad_norm': 1.3601247072219849, 'learning_rate': 1.2e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 130/1090 [15:44<1:57:10,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1846, 'grad_norm': 0.662755012512207, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 140/1090 [16:58<1:59:16,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2091, 'grad_norm': 7.288661003112793, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 150/1090 [18:13<1:56:49,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1104, 'grad_norm': 2.9848265647888184, 'learning_rate': 1.5e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 160/1090 [19:27<1:55:20,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1221, 'grad_norm': 4.778802871704102, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 170/1090 [20:41<1:51:33,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0925, 'grad_norm': 0.27340999245643616, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 180/1090 [21:53<1:49:15,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0655, 'grad_norm': 1.6913907527923584, 'learning_rate': 1.8e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 190/1090 [23:06<1:46:32,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0882, 'grad_norm': 5.564198970794678, 'learning_rate': 1.9e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 200/1090 [24:19<1:47:19,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0697, 'grad_norm': 2.355030059814453, 'learning_rate': 2e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 210/1090 [25:31<1:45:24,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0867, 'grad_norm': 1.0826959609985352, 'learning_rate': 2.1e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 220/1090 [26:44<1:45:09,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0797, 'grad_norm': 8.970026969909668, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 230/1090 [27:57<1:45:46,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.204, 'grad_norm': 0.7986243367195129, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 240/1090 [29:09<1:41:54,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0859, 'grad_norm': 2.6408474445343018, 'learning_rate': 2.4e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 250/1090 [30:21<1:41:29,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1281, 'grad_norm': 11.924275398254395, 'learning_rate': 2.5e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 260/1090 [31:33<1:38:33,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2396, 'grad_norm': 2.4409587383270264, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 270/1090 [32:45<1:37:10,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0388, 'grad_norm': 0.22552728652954102, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 280/1090 [33:55<1:34:52,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.049, 'grad_norm': 0.10239113867282867, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 290/1090 [35:11<1:39:59,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0959, 'grad_norm': 0.15186285972595215, 'learning_rate': 2.9e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 300/1090 [36:23<1:33:06,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0861, 'grad_norm': 0.43932726979255676, 'learning_rate': 3e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 310/1090 [37:35<1:34:01,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0507, 'grad_norm': 0.08018084615468979, 'learning_rate': 3.1e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 320/1090 [38:47<1:31:32,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1784, 'grad_norm': 6.894588947296143, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 330/1090 [39:58<1:30:02,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.088, 'grad_norm': 4.4864020347595215, 'learning_rate': 3.3e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 340/1090 [41:09<1:28:27,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0518, 'grad_norm': 1.8154315948486328, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 350/1090 [42:20<1:27:52,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0265, 'grad_norm': 12.179049491882324, 'learning_rate': 3.5e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 360/1090 [43:31<1:26:23,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0679, 'grad_norm': 0.04191020503640175, 'learning_rate': 3.6e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 370/1090 [44:41<1:23:50,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1151, 'grad_norm': 23.45888900756836, 'learning_rate': 3.7e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 380/1090 [45:51<1:23:03,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.136, 'grad_norm': 4.181308269500732, 'learning_rate': 3.8e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 390/1090 [47:03<1:23:55,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.039, 'grad_norm': 4.791146755218506, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 400/1090 [48:15<1:23:40,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0225, 'grad_norm': 32.59806442260742, 'learning_rate': 4e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 410/1090 [49:30<1:24:11,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0787, 'grad_norm': 0.13664129376411438, 'learning_rate': 4.1e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 420/1090 [50:48<1:30:24,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0303, 'grad_norm': 0.20217449963092804, 'learning_rate': 4.2e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 430/1090 [52:05<1:23:09,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1098, 'grad_norm': 0.03950214385986328, 'learning_rate': 4.3e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 440/1090 [53:21<1:23:15,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.079, 'grad_norm': 21.04144859313965, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 450/1090 [54:38<1:21:01,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0502, 'grad_norm': 0.34277281165122986, 'learning_rate': 4.5e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 460/1090 [55:53<1:19:01,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0156, 'grad_norm': 7.462057113647461, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 470/1090 [57:10<1:20:28,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0686, 'grad_norm': 0.07675110548734665, 'learning_rate': 4.7e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 480/1090 [58:28<1:17:26,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0983, 'grad_norm': 0.06784369051456451, 'learning_rate': 4.8e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 490/1090 [59:43<1:15:17,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0874, 'grad_norm': 3.6417031288146973, 'learning_rate': 4.9e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 500/1090 [1:00:59<1:14:15,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1014, 'grad_norm': 6.946353912353516, 'learning_rate': 5e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 510/1090 [1:02:21<1:15:06,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0537, 'grad_norm': 5.706919193267822, 'learning_rate': 4.915254237288136e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 520/1090 [1:03:36<1:10:07,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1805, 'grad_norm': 10.499643325805664, 'learning_rate': 4.8305084745762714e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 530/1090 [1:04:49<1:08:41,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0335, 'grad_norm': 8.50383186340332, 'learning_rate': 4.745762711864407e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 540/1090 [1:06:03<1:07:40,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0729, 'grad_norm': 11.516900062561035, 'learning_rate': 4.6610169491525425e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 550/1090 [1:07:17<1:06:45,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.016, 'grad_norm': 16.39923667907715, 'learning_rate': 4.5762711864406784e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 560/1090 [1:08:31<1:04:33,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'grad_norm': 0.018616262823343277, 'learning_rate': 4.491525423728814e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 570/1090 [1:09:46<1:05:45,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0246, 'grad_norm': 0.013836686499416828, 'learning_rate': 4.4067796610169495e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 580/1090 [1:11:00<1:02:41,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0588, 'grad_norm': 0.010019143112003803, 'learning_rate': 4.3220338983050854e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 590/1090 [1:12:14<1:01:12,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0355, 'grad_norm': 0.011815634556114674, 'learning_rate': 4.2372881355932206e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 600/1090 [1:13:25<55:34,  6.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0021, 'grad_norm': 0.024275578558444977, 'learning_rate': 4.152542372881356e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 610/1090 [1:14:32<53:20,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0418, 'grad_norm': 0.023586010560393333, 'learning_rate': 4.067796610169492e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 620/1090 [1:15:42<54:57,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0226, 'grad_norm': 0.51836097240448, 'learning_rate': 3.983050847457627e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 630/1090 [1:16:49<52:07,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.013, 'grad_norm': 0.053257424384355545, 'learning_rate': 3.898305084745763e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 640/1090 [1:18:05<56:46,  7.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'grad_norm': 0.015742238610982895, 'learning_rate': 3.813559322033898e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 650/1090 [1:19:18<53:38,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0838, 'grad_norm': 10.177223205566406, 'learning_rate': 3.728813559322034e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 660/1090 [1:20:31<52:24,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0292, 'grad_norm': 8.481857299804688, 'learning_rate': 3.644067796610169e-05, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 670/1090 [1:21:46<53:52,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0215, 'grad_norm': 3.3174996376037598, 'learning_rate': 3.559322033898305e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 680/1090 [1:23:00<50:10,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0099, 'grad_norm': 0.0672106146812439, 'learning_rate': 3.474576271186441e-05, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 690/1090 [1:24:13<48:39,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0121, 'grad_norm': 0.012930461205542088, 'learning_rate': 3.389830508474576e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 700/1090 [1:25:26<47:37,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0591, 'grad_norm': 0.02857023850083351, 'learning_rate': 3.305084745762712e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 710/1090 [1:26:39<46:23,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1132, 'grad_norm': 12.443567276000977, 'learning_rate': 3.2203389830508473e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 720/1090 [1:27:52<45:14,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0111, 'grad_norm': 0.3938584625720978, 'learning_rate': 3.135593220338983e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 730/1090 [1:29:05<43:55,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0011, 'grad_norm': 0.015520231798291206, 'learning_rate': 3.050847457627119e-05, 'epoch': 1.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 740/1090 [1:30:20<44:32,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0355, 'grad_norm': 0.0244954451918602, 'learning_rate': 2.9661016949152544e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 750/1090 [1:31:33<41:24,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'grad_norm': 0.012760709971189499, 'learning_rate': 2.88135593220339e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 760/1090 [1:32:46<40:00,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1479, 'grad_norm': 4.254879474639893, 'learning_rate': 2.7966101694915255e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 770/1090 [1:34:01<40:34,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0013, 'grad_norm': 0.03529846668243408, 'learning_rate': 2.711864406779661e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 780/1090 [1:35:16<38:04,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0039, 'grad_norm': 0.015308834612369537, 'learning_rate': 2.627118644067797e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 790/1090 [1:36:29<36:21,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0223, 'grad_norm': 0.8675014972686768, 'learning_rate': 2.5423728813559322e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 800/1090 [1:37:43<35:48,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0245, 'grad_norm': 5.718473434448242, 'learning_rate': 2.457627118644068e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 810/1090 [1:38:58<34:39,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0251, 'grad_norm': 0.6613492965698242, 'learning_rate': 2.3728813559322036e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 820/1090 [1:40:11<32:54,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0404, 'grad_norm': 0.00762080866843462, 'learning_rate': 2.2881355932203392e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 830/1090 [1:41:23<30:54,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0124, 'grad_norm': 0.32322460412979126, 'learning_rate': 2.2033898305084748e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 840/1090 [1:42:36<30:28,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'grad_norm': 0.031235724687576294, 'learning_rate': 2.1186440677966103e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 850/1090 [1:43:51<30:08,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0022, 'grad_norm': 0.04911212995648384, 'learning_rate': 2.033898305084746e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 860/1090 [1:45:04<27:55,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0024, 'grad_norm': 0.006674684584140778, 'learning_rate': 1.9491525423728814e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 870/1090 [1:46:17<26:51,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0125, 'grad_norm': 0.01004003919661045, 'learning_rate': 1.864406779661017e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 880/1090 [1:47:31<26:06,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0098, 'grad_norm': 0.29049360752105713, 'learning_rate': 1.7796610169491526e-05, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 890/1090 [1:48:38<22:30,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0253, 'grad_norm': 0.0066713192500174046, 'learning_rate': 1.694915254237288e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 900/1090 [1:49:52<23:11,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0265, 'grad_norm': 0.037539899349212646, 'learning_rate': 1.6101694915254237e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 910/1090 [1:51:05<21:43,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0066130440682172775, 'learning_rate': 1.5254237288135596e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 920/1090 [1:52:18<21:05,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'grad_norm': 0.0094094043597579, 'learning_rate': 1.440677966101695e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 930/1090 [1:53:31<19:29,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.031, 'grad_norm': 14.157710075378418, 'learning_rate': 1.3559322033898305e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 940/1090 [1:54:44<18:24,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0474, 'grad_norm': 0.005907065235078335, 'learning_rate': 1.2711864406779661e-05, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 950/1090 [1:55:57<16:57,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0014, 'grad_norm': 0.1195366308093071, 'learning_rate': 1.1864406779661018e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 960/1090 [1:57:10<15:47,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'grad_norm': 0.006805360782891512, 'learning_rate': 1.1016949152542374e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 970/1090 [1:58:23<14:29,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0394, 'grad_norm': 0.15279391407966614, 'learning_rate': 1.016949152542373e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 980/1090 [1:59:36<13:15,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0222, 'grad_norm': 0.3049929440021515, 'learning_rate': 9.322033898305085e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 990/1090 [2:00:48<12:09,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.005016120616346598, 'learning_rate': 8.47457627118644e-06, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1000/1090 [2:02:00<10:50,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0506, 'grad_norm': 0.010985421016812325, 'learning_rate': 7.627118644067798e-06, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1010/1090 [2:03:20<10:07,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0108, 'grad_norm': 0.06705741584300995, 'learning_rate': 6.779661016949153e-06, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1020/1090 [2:04:35<08:46,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0053415363654494286, 'learning_rate': 5.932203389830509e-06, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1030/1090 [2:05:48<07:17,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.0054967934265732765, 'learning_rate': 5.084745762711865e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1040/1090 [2:07:00<06:01,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0289, 'grad_norm': 0.004431853070855141, 'learning_rate': 4.23728813559322e-06, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1050/1090 [2:08:13<04:48,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0408, 'grad_norm': 0.005802992265671492, 'learning_rate': 3.3898305084745763e-06, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1060/1090 [2:09:24<03:31,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.002, 'grad_norm': 0.007020679768174887, 'learning_rate': 2.5423728813559323e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1070/1090 [2:10:34<02:18,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'grad_norm': 0.004613779950886965, 'learning_rate': 1.6949152542372882e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1080/1090 [2:11:42<01:04,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'grad_norm': 0.003217482240870595, 'learning_rate': 8.474576271186441e-07, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090/1090 [2:12:45<00:00,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'grad_norm': 0.005734020844101906, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090/1090 [2:12:47<00:00,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7967.2003, 'train_samples_per_second': 2.189, 'train_steps_per_second': 0.137, 'train_loss': 0.0989107018135864, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1090, training_loss=0.0989107018135864, metrics={'train_runtime': 7967.2003, 'train_samples_per_second': 2.189, 'train_steps_per_second': 0.137, 'total_flos': 2309966497763328.0, 'train_loss': 0.0989107018135864, 'epoch': 2.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [03:25<00:00,  1.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.017079537734389305,\n",
       " 'eval_runtime': 207.1078,\n",
       " 'eval_samples_per_second': 10.526,\n",
       " 'eval_steps_per_second': 0.661,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [03:32<00:00,  1.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.91339  , -4.7248683],\n",
       "       [-3.5898714,  3.8752549],\n",
       "       [-3.5908644,  3.9313364],\n",
       "       ...,\n",
       "       [-3.383893 ,  3.6332774],\n",
       "       [ 2.9832778, -2.8182068],\n",
       "       [ 4.9017305, -4.6804433]], dtype=float32), label_ids=array([0, 1, 1, ..., 1, 0, 0], dtype=int64), metrics={'test_loss': 0.017079537734389305, 'test_runtime': 214.3257, 'test_samples_per_second': 10.171, 'test_steps_per_second': 0.639})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [03:24<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "output=trainer.predict(test_dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1596,    0],\n",
       "       [   0,  584]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(y_test,output)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [03:15<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "prediction_output = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(prediction_output.predictions, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99, F1: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "acc = accuracy_score(prediction_output.label_ids, predicted_labels)\n",
    "f1 = f1_score(prediction_output.label_ids, predicted_labels, average='weighted')\n",
    "print(f\"Accuracy: {acc:.2f}, F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [03:06<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017079537734389305, 'eval_runtime': 187.754, 'eval_samples_per_second': 11.611, 'eval_steps_per_second': 0.73, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test dataset (which contains labels)\n",
    "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./model/email_spam_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in d:\\miniconda3\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\miniconda3\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"token\")  # Lấy token từ https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_args.bin: 100%|██████████| 5.18k/5.18k [00:01<00:00, 4.79kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jamesnq/email_spam_model/commit/dda7c1ea14d7bbb37cf0d088ad8ea5db63bfafbe', commit_message='Upload folder using huggingface_hub', commit_description='', oid='dda7c1ea14d7bbb37cf0d088ad8ea5db63bfafbe', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jamesnq/email_spam_model', endpoint='https://huggingface.co', repo_type='model', repo_id='jamesnq/email_spam_model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_folder\n",
    "\n",
    "repo_id = \"jamesnq/email_spam_model\"  # Tên repo trên Hugging Face\n",
    "local_folder = \"email_spam_model\"  # Thư mục chứa model đã cập nhật\n",
    "\n",
    "upload_folder(folder_path=local_folder, repo_id=repo_id, repo_type=\"model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
